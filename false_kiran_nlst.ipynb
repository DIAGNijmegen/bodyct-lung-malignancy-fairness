{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "from scipy.stats import pearsonr, spearmanr, ks_2samp, mannwhitneyu, ttest_ind\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utilities import data\n",
    "\n",
    "## directory where results are\n",
    "EXPERIMENT_DIR = f\"/data/bodyct/experiments/lung-malignancy-fairness-shaurya\"\n",
    "NLST_PREDS = f\"{EXPERIMENT_DIR}/nlst\"\n",
    "\n",
    "TEAMS_DIR = \"C:/Users/shaur/OneDrive - Radboudumc/Documents - Master - Shaurya Gaur/General/Malignancy-Estimation Results\"\n",
    "NLST_PREDS = f\"{TEAMS_DIR}/nlst\" ## Comment out if not using Teams backup (aka Chansey is up :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlst_preds_nodule = pd.read_csv(f\"{NLST_PREDS}/nlst_demov4_allmodels_cal.csv\")\n",
    "nlst_preds_nodule.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{NLST_PREDS}/nlst_demo_v4_cols.json') as json_data:\n",
    "    nlst_democols = json.load(json_data)\n",
    "    json_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlst_democols['num'].pop('nodule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlst_democols['num']['other'].append('Mean_Entropy_Kiran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlst_democols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlst_preds, nlst_democols, MODELS = data.prep_nlst_preds(nlst_preds_nodule, nlst_democols, scanlevel=False, tijmen=False, sybil=False)\n",
    "nlst_preds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlst_policy_thresholds = pd.read_csv(f\"{NLST_PREDS}/policy-thresholds-{len(nlst_preds)}.csv\", index_col=0)\n",
    "# nlst_policy_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 'Brock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlst_preds['WhiteOrBlack'] = nlst_preds['race'].replace([3, 4, 5, 6], value=np.nan, inplace=False)\n",
    "nlst_democols['cat']['demo'].append('WhiteOrBlack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TO_COL = {\n",
    "    \"Venkadesh\": \"DL_cal\",\n",
    "    # \"de Haas Combined\": \"Thijmen_mean_cal\",\n",
    "    \"de Haas Local\": \"Thijmen_local_cal\",\n",
    "    \"de Haas Global (hidden nodule)\": \"Thijmen_global_hidden\",\n",
    "    \"de Haas Global (w/nodule)\": \"Thijmen_global_show_cal\",\n",
    "    \"Sybil\": \"sybil_year1\",\n",
    "    \"PanCan2b\": \"PanCan2b\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlst_preds['Kiran_pred_label'] = (nlst_preds[MODEL_TO_COL['Venkadesh']] > nlst_policy_thresholds.loc['Venkadesh', THRESHOLD]).astype(int).to_numpy()\n",
    "nlst_preds['Kiran_pred_label'] = (nlst_preds[MODEL_TO_COL['Venkadesh']] > 0.06).astype(int).to_numpy()\n",
    "nlst_preds_nodule['Kiran_pred_label'] = (nlst_preds_nodule[MODEL_TO_COL['Venkadesh']] > 0.06).astype(int).to_numpy()\n",
    "nlst_preds['Kiran_PanCan_diff'] = nlst_preds[MODEL_TO_COL['Venkadesh']] - nlst_preds['PanCan2b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = nlst_preds_nodule.query(\"label == 0 and Kiran_pred_label == 1\")\n",
    "false_negatives = nlst_preds_nodule.query(\"label == 1 and Kiran_pred_label == 0\")\n",
    "\n",
    "true_positives = nlst_preds_nodule.query(\"label == 1 and Kiran_pred_label == 1\")\n",
    "true_negatives = nlst_preds_nodule.query(\"label == 0 and Kiran_pred_label == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between Training Info Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sets = {\n",
    "    \"FP\": false_positives,\n",
    "    \"FN\": false_negatives,\n",
    "    \"TP\": true_positives,\n",
    "    \"TN\": true_negatives, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_col_dfs(cols=nlst_democols['cat'], df_func=pd.DataFrame, dfsets=result_sets, dispdf=False):\n",
    "    splitdfs = []\n",
    "    for cat in cols:\n",
    "        if dispdf: display(Markdown(f\"### {cat}\"))\n",
    "        \n",
    "        for c in cols[cat]:\n",
    "            df = df_func(c, dfsets)\n",
    "            if dispdf: display(df)\n",
    "\n",
    "            df['category'] = [cat] * len(df)\n",
    "            df['attribute'] = [c] * len(df)\n",
    "            df['value'] = df.index.values\n",
    "            \n",
    "            dfcols = df.columns.tolist()\n",
    "            dfcols = dfcols[-3:] + dfcols[:-3]\n",
    "            df = df[dfcols]\n",
    "            df.reset_index(inplace=True, drop=True)\n",
    "            df.sort_values(by='value', ascending=True, inplace=True)\n",
    "\n",
    "            splitdfs.append(df)\n",
    "\n",
    "    return pd.concat(splitdfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_dist_df(c='Gender', dfsets=result_sets):\n",
    "    dfdict = {}\n",
    "    for m in dfsets:\n",
    "        dfdict[f\"{m}_freq\"] = dfsets[m][c].value_counts(normalize=False, dropna=False).astype(int)\n",
    "        dfdict[f\"{m}_norm\"] = 100 * dfsets[m][c].value_counts(normalize=True, dropna=False).round(6)\n",
    "        dfdict[f\"{m}_freq\"].fillna(0, inplace=True)\n",
    "        dfdict[f\"{m}_norm\"].fillna(0, inplace=True)\n",
    "    \n",
    "    for i, m1 in enumerate(dfsets):\n",
    "        for j, m2 in enumerate(dfsets):\n",
    "            if j > i:\n",
    "                # dfdict[f\"diff_freq_{m1}_{m2}\"] = (dfdict[f\"{m1}_freq\"] - dfdict[f\"{m2}_freq\"]).round(4)\n",
    "                dfdict[f\"diff_norm_{m1}_{m2}\"] = (dfdict[f\"{m1}_norm\"] - dfdict[f\"{m2}_norm\"]).round(4)\n",
    "    \n",
    "    df = pd.DataFrame(dfdict).drop_duplicates()\n",
    "\n",
    "    for m in dfsets:\n",
    "        df[f\"{m}_freq\"] = df[f\"{m}_freq\"].fillna(0.0)\n",
    "        df[f\"{m}_norm\"] = df[f\"{m}_norm\"].fillna(0.0)\n",
    "\n",
    "    for i, m1 in enumerate(dfsets):\n",
    "        for j, m2 in enumerate(dfsets):\n",
    "            if j > i:\n",
    "                # dfdict[f\"diff_freq_{m1}_{m2}\"] = (dfdict[f\"{m1}_freq\"] - dfdict[f\"{m2}_freq\"]).round(4)\n",
    "                df[f\"diff_norm_{m1}_{m2}\"] = (df[f\"{m1}_norm\"] - df[f\"{m2}_norm\"]).round(4)    \n",
    "\n",
    "    # df = pd.DataFrame(dfdict).drop_duplicates()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_dist_df(c='Gender', dfsets=result_sets):\n",
    "    dfdict = {}\n",
    "    for m in dfsets:\n",
    "        dfdict[f\"{m}\"] = dfsets[m][c].describe(percentiles=[0.5]).round(4)\n",
    "    \n",
    "    for i, m1 in enumerate(dfsets):\n",
    "        for j, m2 in enumerate(dfsets):\n",
    "            if j > i:\n",
    "                dfdict[f\"diff_{m1}_{m2}\"] = dfdict[f\"{m1}\"] - dfdict[f\"{m2}\"]\n",
    "    \n",
    "    df = pd.DataFrame(dfdict).drop_duplicates()\n",
    "    df.drop(index=['count', 'max', 'min', 'std'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_demo_splits = combine_col_dfs(nlst_democols['cat'], cat_dist_df, result_sets).query('value != 0')\n",
    "display(cat_demo_splits.sort_values(by='diff_norm_FP_FN', ascending=False).head(30))\n",
    "cat_demo_splits.sort_values(by='diff_norm_FP_FN', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_demo_splits = combine_col_dfs(nlst_democols['num'], num_dist_df, result_sets)\n",
    "display(num_demo_splits.sort_values(by='diff_FP_FN', ascending=False).head(30))\n",
    "num_demo_splits.sort_values(by='diff_FP_FN', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with the top 100 scores that were different from PanCan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_top_100_diff = {\n",
    "    \"FP\": false_positives.sort_values(by=['Kiran_PanCan_diff'], ascending=False)[0:100],\n",
    "    \"FN\": false_negatives.sort_values(by=['Kiran_PanCan_diff'], ascending=False)[0:100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_demo_splits = combine_col_dfs(nlst_democols['cat'], cat_dist_df, result_top_100_diff).query('value != 0')\n",
    "display(cat_demo_splits.sort_values(by='diff_norm_FP_FN', ascending=False).head(30))\n",
    "cat_demo_splits.sort_values(by='diff_norm_FP_FN', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_demo_splits = combine_col_dfs(nlst_democols['num'], num_dist_df, result_top_100_diff)\n",
    "display(num_demo_splits.sort_values(by='diff_FP_FN', ascending=False).head(30))\n",
    "num_demo_splits.sort_values(by='diff_FP_FN', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = nlst_preds_nodule.query(\"label == 0 and Kiran_pred_label == 1\")\n",
    "false_positives.sort_values(by=['Kiran_PanCan_diff'], ascending=False)[['label', 'Kiran_pred_label', 'PanCan2b', 'DL_cal', 'Kiran_PanCan_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(false_positives, x='Kiran_PanCan_diff', hue='race', multiple='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Racial differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_fps = {\n",
    "    \"white\": false_positives.query(\"race == 1\"),\n",
    "    \"black\": false_positives.query(\"race == 2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_demo_splits = combine_col_dfs(nlst_democols['cat'], cat_dist_df, race_fps).query('value != 0')\n",
    "display(cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=False).head(30))\n",
    "cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_demo_splits = combine_col_dfs(nlst_democols['num'], num_dist_df, race_fps)\n",
    "display(num_demo_splits.sort_values(by='diff_white_black', ascending=False).head(30))\n",
    "num_demo_splits.sort_values(by='diff_white_black', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives.sort_values(by=['Kiran_PanCan_diff'], ascending=True)[['label', 'Kiran_pred_label', 'PanCan2b', 'DL_cal', 'Kiran_PanCan_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(false_negatives, x='Kiran_PanCan_diff', hue='race', multiple='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Racial differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_fns = {\n",
    "    \"white\": false_negatives.query(\"race == 1\"),\n",
    "    \"black\": false_negatives.query(\"race == 2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in race_fns:\n",
    "    print(m, len(race_fns[m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_demo_splits = combine_col_dfs(nlst_democols['cat'], cat_dist_df, race_fns).query('value != 0')\n",
    "display(cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=False).head(30))\n",
    "cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=False).query('category == \"nodule\"'))\n",
    "cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=True).query('category == \"nodule\"')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=False).query('attribute == \"LC_stage\"'))\n",
    "cat_demo_splits.sort_values(by='diff_norm_white_black', ascending=True).query('attribute == \"LC_stage\"')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_demo_splits = combine_col_dfs(nlst_democols['num'], num_dist_df, race_fns)\n",
    "display(num_demo_splits.sort_values(by='diff_white_black', ascending=False).head(30))\n",
    "num_demo_splits.sort_values(by='diff_white_black', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds, x='pkyr', hue='WhiteOrBlack', common_norm=False, element='bars', kde=True, stat='probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds.query('label == 0'), x='Mean_Entropy_Kiran', hue='NoduleType', common_norm=False, element='bars', kde=True, stat='probability')\n",
    "nlst_preds.query('label == 0').groupby('NoduleType')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds.query('label == 1'), x='Mean_Entropy_Kiran', hue='NoduleType', common_norm=False, element='bars', kde=True, stat='probability')\n",
    "nlst_preds.query('label == 1').groupby('NoduleType')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds.query('label == 0'), x='Mean_Entropy_Kiran', hue='WhiteOrBlack', common_norm=False, element='bars', kde=True, stat='probability')\n",
    "nlst_preds.query('label == 0').groupby('WhiteOrBlack')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds.query('label == 1'), x='Mean_Entropy_Kiran', hue='WhiteOrBlack', common_norm=False, element='bars', kde=True, stat='probability')\n",
    "nlst_preds.query('label == 1').groupby('WhiteOrBlack')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=false_negatives, x='Mean_Entropy_Kiran', hue='WhiteOrBlack', common_norm=False, element='bars', kde=True, stat='density')\n",
    "false_negatives.groupby('WhiteOrBlack')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=false_positives, x='Mean_Entropy_Kiran', hue='WhiteOrBlack', common_norm=False, element='bars', kde=True, stat='density')\n",
    "false_positives.groupby('WhiteOrBlack')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds, x='Mean_Entropy_Kiran', hue='diaghype', common_norm=False, element='bars', kde=True, stat='density')\n",
    "nlst_preds.groupby('diaghype')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=false_negatives, x='Mean_Entropy_Kiran', hue='diaghype', common_norm=False, element='bars', kde=True, stat='density')\n",
    "false_negatives.groupby('diaghype')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=false_positives, x='Mean_Entropy_Kiran', hue='diaghype', common_norm=False, element='bars', kde=True, stat='density')\n",
    "false_positives.groupby('diaghype')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds.query('label == 1'), x='Mean_Entropy_Kiran', hue='diaghype', common_norm=False, element='bars', kde=True, stat='density')\n",
    "nlst_preds.query('label == 1').groupby('diaghype')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=nlst_preds.query('label == 0'), x='Mean_Entropy_Kiran', hue='diaghype', common_norm=False, element='bars', kde=True, stat='density')\n",
    "nlst_preds.query('label == 0').groupby('diaghype')['Mean_Entropy_Kiran'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty by all factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlst_preds_nodule.query('label == 0').groupby('LC_stage')['Mean_Entropy_Kiran'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertainty_by_attributes(df):\n",
    "    infodicts = []\n",
    "    for category in nlst_democols['cat']:\n",
    "        for attribute in nlst_democols['cat'][category]:\n",
    "            info = {\n",
    "                \"category\": category,\n",
    "                \"attribute\": attribute,\n",
    "                \"diff_avg\": 0,\n",
    "                \"diff_med\": 0,\n",
    "                \"p-mannwhitney\": 1,\n",
    "                \"p-kstest\": 1,\n",
    "            }\n",
    "            if len(df.groupby(attribute)['Mean_Entropy_Kiran']) == 0: continue\n",
    "\n",
    "            uncertainty_df = df.groupby(attribute)['Mean_Entropy_Kiran'].describe()\n",
    "            if len(uncertainty_df) < 2: continue\n",
    "\n",
    "            ## Get top 2 subgroups.\n",
    "            uncertainty_df = uncertainty_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "            for i, (subgroup, stats) in enumerate(uncertainty_df.iterrows()):\n",
    "                if i > 1: continue\n",
    "                info[f\"group{i+1}\"] = subgroup\n",
    "                info[f\"group{i+1}_num\"] = stats['count']\n",
    "                info[f\"group{i+1}_avg\"] = stats['mean']\n",
    "                info[f\"group{i+1}_std\"] = stats['std']\n",
    "                info[f\"group{i+1}_med\"] = stats['50%']\n",
    "                info[f\"group{i+1}_iqr\"] = stats['75%'] - stats['25%']\n",
    "\n",
    "            info[f\"diff_avg\"] = info[f\"group1_avg\"] - info[f\"group2_avg\"]\n",
    "            info[f\"diff_med\"] = info[f\"group1_med\"] - info[f\"group2_med\"]\n",
    "            \n",
    "            _, info[\"p-mannwhitney\"] = mannwhitneyu(\n",
    "                df[df[attribute] == info[\"group1\"]]['Mean_Entropy_Kiran'], \n",
    "                df[df[attribute] == info[\"group2\"]]['Mean_Entropy_Kiran'], \n",
    "                alternative='two-sided', nan_policy='omit')\n",
    "\n",
    "            _, info[\"p-kstest\"] = ks_2samp(\n",
    "                df[df[attribute] == info[\"group1\"]]['Mean_Entropy_Kiran'], \n",
    "                df[df[attribute] == info[\"group2\"]]['Mean_Entropy_Kiran'], \n",
    "                alternative='two-sided', nan_policy='omit')\n",
    "            \n",
    "            infodicts.append(info)\n",
    "    \n",
    "    categorical_df = pd.DataFrame(infodicts).sort_values(by=['p-kstest', 'p-mannwhitney', 'diff_avg'], ascending=[True, True, True])\n",
    "\n",
    "    numinfo = []\n",
    "    for category in nlst_democols['num']:\n",
    "        for attribute in nlst_democols['num'][category]:\n",
    "            df2 = df.dropna(axis=0, subset=[attribute, 'Mean_Entropy_Kiran'])\n",
    "            src, pval = spearmanr(df2['Mean_Entropy_Kiran'], df2[attribute])\n",
    "            info = {\n",
    "                \"category\": category,\n",
    "                \"attribute\": attribute,\n",
    "                \"correlation\": src,\n",
    "                \"p\": pval,\n",
    "            }\n",
    "            numinfo.append(info)\n",
    "    \n",
    "    numerical_df = pd.DataFrame(numinfo).sort_values(by='p', ascending=True)\n",
    "    return categorical_df, numerical_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodule_uncertainty_diffs, nodule_uncertainty_corrs = get_uncertainty_by_attributes(nlst_preds_nodule)\n",
    "display(nodule_uncertainty_diffs)\n",
    "display(nodule_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_uncertainty_diffs, scan_uncertainty_corrs = get_uncertainty_by_attributes(nlst_preds)\n",
    "display(scan_uncertainty_diffs)\n",
    "display(scan_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_uncertainty_diffs, malignant_uncertainty_corrs = get_uncertainty_by_attributes(nlst_preds_nodule.query('label == 1'))\n",
    "display(malignant_uncertainty_diffs)\n",
    "display(malignant_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_uncertainty_diffs, benign_uncertainty_corrs = get_uncertainty_by_attributes(nlst_preds_nodule.query('label == 0'))\n",
    "display(benign_uncertainty_diffs)\n",
    "display(benign_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_uncertainty_diffs, fp_uncertainty_corrs = get_uncertainty_by_attributes(false_positives)\n",
    "display(fp_uncertainty_diffs)\n",
    "display(fp_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_uncertainty_diffs, fn_uncertainty_corrs = get_uncertainty_by_attributes(false_negatives)\n",
    "display(fn_uncertainty_diffs)\n",
    "display(fn_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_uncertainty_diffs, tp_uncertainty_corrs = get_uncertainty_by_attributes(true_positives)\n",
    "display(tp_uncertainty_diffs)\n",
    "display(tp_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_uncertainty_diffs, positive_uncertainty_corrs = get_uncertainty_by_attributes(nlst_preds.query('Kiran_pred_label == 1'))\n",
    "display(positive_uncertainty_diffs)\n",
    "display(positive_uncertainty_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_uncertainty_diffs, negative_uncertainty_corrs = get_uncertainty_by_attributes(nlst_preds.query('Kiran_pred_label == 0'))\n",
    "display(negative_uncertainty_diffs)\n",
    "display(negative_uncertainty_corrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
