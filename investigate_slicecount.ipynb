{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import sys\n",
    "\n",
    "TEAMS_DIR = \"C:/Users/shaur/OneDrive - Radboudumc/Documents - Master - Shaurya Gaur/General/Malignancy-Estimation Results\"\n",
    "NLST_PREDS = f\"{TEAMS_DIR}/nlst\" ## Comment out if not using Teams backup (aka Chansey is up :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(file_path):\n",
    "    # Read the MHA file using SimpleITK\n",
    "    image = sitk.ReadImage(file_path)\n",
    "    # Get the size of the image (in the form [x, y, z])\n",
    "    return image.GetSize()\n",
    "\n",
    "def get_image_sizes_from_dataframe(df, directory):\n",
    "    # Create a list to store results\n",
    "    sizes = []\n",
    "\n",
    "    # Loop through the filenames in the dataframe\n",
    "    for i, filename in enumerate(df['SeriesInstanceUID']):\n",
    "        file_path = os.path.join(directory, f\"{filename}.mha\")\n",
    "        try:\n",
    "            size = get_image_size(file_path)\n",
    "            print(f\"{i+1} / {len(df)}: {filename}.mha ... size = {size}\", end=\"\\r\")\n",
    "            sizes.append((filename, size[0], size[1], size[2]))  # Include filename in the result\n",
    "        except Exception as e:\n",
    "            print(f\"{i+1} / {len(df)}: {filename}.mha ... ERROR = {e}\", end=\"\\r\")\n",
    "            sizes.append((filename, None, None, None))  # If an error occurs, append None for all dimensions\n",
    "\n",
    "    # Create a new dataframe with filename, x, y, z columns\n",
    "    sizes_df = pd.DataFrame(sizes, columns=['SeriesInstanceUID', 'series_x', 'series_y', 'series_z'])\n",
    "    return sizes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10183: 1.2.840.113654.2.55.240231128564881525363489796879328810792.mha ... size = (512, 512, 162)\r"
     ]
    }
   ],
   "source": [
    "directory_path = 'W:/experiments/0-nlst-mha' \n",
    "df = pd.read_csv(f'{NLST_PREDS}/nlst_demov4_allmodels_cal.csv').drop_duplicates(subset='SeriesInstanceUID')\n",
    "\n",
    "# Get image sizes and append to the original DataFrame\n",
    "sizes_df = get_image_sizes_from_dataframe(df, directory_path)\n",
    "sizes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can concatenate it back with the original dataframe:\n",
    "merged_df = pd.merge(df, sizes_df, on='filename', how='left')\n",
    "print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
